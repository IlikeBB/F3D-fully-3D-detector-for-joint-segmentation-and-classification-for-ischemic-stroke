{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.model_3d_denseunet import threed_unet\n",
    "from utils.model_1 import get_model\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "MRI_nii_folder_path = 'nii_save_np/lacune/'\n",
    "cv = 3\n",
    "# S1------------------------------------------\n",
    "train_val_path1 = np.load(MRI_nii_folder_path+f'cv{cv}_path_train_val.npy')\n",
    "train_val_x1 = np.load(MRI_nii_folder_path+f'cv{cv}_x_strain_val.npy')\n",
    "train_val_y1 = np.load(MRI_nii_folder_path+f'cv{cv}_y_strain_val.npy')\n",
    "\n",
    "print(train_val_x1.shape, train_val_y1.shape, train_val_path1.shape)\n",
    "# S2------------------------------------------\n",
    "train_val_x2 = np.load(MRI_nii_folder_path+f'cv{cv}_x_ctrain_val.npy')\n",
    "train_val_y2 = np.load(MRI_nii_folder_path+f'cv{cv}_y_ctrain_val.npy')\n",
    "print(train_val_x2.shape, train_val_y2.shape, train_val_path1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = int(train_val_x1.shape[0]*0.8)\n",
    "x_val1 = train_val_x1[ds:].astype(np.float32)\n",
    "y_val1 = train_val_y1[ds:].astype(np.float32)\n",
    "valid_path1 = train_val_path1[ds:]\n",
    "x_val2 = train_val_x2[ds:].astype(np.float32)\n",
    "y_val2 = train_val_y2[ds:].astype(np.float32)\n",
    "valid_path2 = train_val_path1[ds:]\n",
    "print(x_val1.shape, y_val1.shape)\n",
    "print(x_val2.shape, y_val2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_name1 = f'pair_L_154_3DUnet_binary_batch-1_focal_tversky_leaky_aug_Adam-lr-1e-5_cv{cv}_t4.hdf5'\n",
    "weight_name2 = f'154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv{cv}_t1_cw.h5'\n",
    "weight_path1 = '3d_mask_classification/checkpoint/2_class/binary1/' + weight_name1\n",
    "weight_path2 = 'chekpoint/lacune/' + weight_name2\n",
    "print(weight_path1)\n",
    "print(weight_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1------------------------------------------\n",
    "print('-'*30)\n",
    "print('Loading S1 saved weights...')\n",
    "print('-'*30)\n",
    "model1 = threed_unet(img_depth=32, img_rows=192, img_cols=192)\n",
    "model1.load_weights(weight_path1)\n",
    "Results = model1.predict(x_val1, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Results.shape)\n",
    "Results1 = np.squeeze(Results)\n",
    "print(Results1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage1_Result = (np.squeeze(Results1)>0.10).astype(np.int32)\n",
    "print(Stage1_Result.shape)\n",
    "print(x_val1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "from tqdm import tqdm\n",
    "image_mask = np.zeros((x_val1.shape[0],32,192,192))\n",
    "\n",
    "def mask_stroke_area(image_, mask_):\n",
    "    image_save = image_.copy()\n",
    "    for i in range(image_.shape[0]):\n",
    "        for j in range(image_.shape[1]):\n",
    "            for k in range(image_.shape[2]):\n",
    "                if mask_[i][j][k]==0:\n",
    "                    image_save[i][j][k]=0\n",
    "    return image_save\n",
    "\n",
    "# for i in tqdm(range(cost)):\n",
    "for i in tqdm(range(x_val1.shape[0])):\n",
    "    image_mask[i] = mask_stroke_area(x_val1[i],Stage1_Result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S2------------------------------------------\n",
    "print('-'*30)\n",
    "print('Loading S2 saved weights...')\n",
    "print('-'*30)\n",
    "model2 = get_model(depth=32, width=192, height=192, class_num=1)\n",
    "model2.load_weights(weight_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results2 = model2.predict(image_mask, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "argmax_pred = np.reshape((Results2>0.1).astype(int),(len(Results2)))\n",
    "argmax_truth = y_val2.astype(int)\n",
    "Pred_dict ={}\n",
    "Trut_dict ={}\n",
    "nii_data=[]\n",
    "count = 0\n",
    "for i in valid_path1:\n",
    "    nii_data.append(i[-14:-8])\n",
    "\n",
    "result_df = {'nii name':nii_data,\n",
    "             'Prediction': argmax_pred,\n",
    "             'GroundTruth':argmax_truth\n",
    "            }\n",
    "results_df = pd.DataFrame(result_df)\n",
    "print('|0 = Lacune |  | 1 = Non-Lacune|\\n')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "cm = confusion_matrix(argmax_truth, argmax_pred)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "imgs_test = x_val2\n",
    "imgs_mask_test = y_val2\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90,fontsize=15)\n",
    "    plt.yticks(tick_marks, classes,fontsize=15)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20)\n",
    "    \n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label',fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species =['Normal','Anterior','Posterior']\n",
    "species = ['Lacune', 'Non-Lacune']\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm, species)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
