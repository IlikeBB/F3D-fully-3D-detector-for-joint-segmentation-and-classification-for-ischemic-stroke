{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, os, cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.executing_eagerly()\n",
    "from tensorflow import keras\n",
    "# Display\n",
    "from keras import backend as K\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 192\n",
    "depth = 32\n",
    "seed = 2\n",
    "# seed: cv1=1 cv2=2 cv3=3\n",
    "save_nii_path='../nii_save_np/all_seg_data/'\n",
    "ALL_nii_path = sorted(os.listdir('../isXXXX_all_mask_and_image/'))\n",
    "print(len(ALL_nii_path))\n",
    "print(ALL_nii_path[0][6:-7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_path=[]\n",
    "image_path=[]\n",
    "for i in ALL_nii_path: #/ssd1/cnn/Classification/is0001-is0154_mask_and_image/is0090s.nii.gz\n",
    "    if 'o' in i:\n",
    "        if 'nii.gz' in i:\n",
    "            image_path.append('../isXXXX_all_mask_and_image/'+i.replace('s.nii.gz','o.nii.gz'))\n",
    "        else:\n",
    "            image_path.append('../isXXXX_all_mask_and_image/'+i.replace('s.nii','o.nii'))\n",
    "    else:\n",
    "        masks_path.append('../isXXXX_all_mask_and_image/'+i)\n",
    "\n",
    "print(len(image_path), len(masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(np.array(image_path[170:-1]))\n",
    "# print(np.array(masks_path[170:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "def normalize(volume, norm_type):\n",
    "    if norm_type == 'zero_mean':\n",
    "        img_o = np.float32(volume.copy())\n",
    "        m = np.mean(img_o)\n",
    "        s = np.std(img_o)\n",
    "        volume = np.divide((img_o - m), s)\n",
    "    elif norm_type == 'div_by_max':\n",
    "        volume = np.divide(volume, np.percentile(volume,98))\n",
    "        \n",
    "    elif norm_type == 'onezero':\n",
    "        for channel in range(volume.shape[-1]):\n",
    "            volume_temp = volume[..., channel]\n",
    "            volume_temp = (volume_temp - np.min(volume_temp)) / (np.max(volume_temp)-np.min(volume_temp))\n",
    "\n",
    "            volume[..., channel] = volume_temp\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "def resize_volume(img,size,depth):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "        # Rotate img shape = (height, wight, depth)\n",
    "    for i in range(img.shape[2]):\n",
    "        img[:,:,i] = np.fliplr(np.flipud(img[:,:,i]))\n",
    "#     img = ndimage.rotate(img, 180, reshape=False, mode=\"nearest\")\n",
    "    img = ndimage.zoom(img, (size/current_height, size/current_width, 1), order=0)\n",
    "    return img\n",
    "\n",
    "def process_scan(path):\n",
    "# get nib first channel\n",
    "    try:\n",
    "        image = nib.load(path)\n",
    "        if len(image.shape) == 4:\n",
    "            image = image.get_fdata()\n",
    "            width,height,queue,_ = image.shape\n",
    "            image = image[:,:,:,1]\n",
    "            image = np.reshape(image,(width,height,queue))\n",
    "        else:\n",
    "            image = image.get_fdata()\n",
    "            pass\n",
    "        volume = normalize(image,\"onezero\")\n",
    "        volume = resize_volume(volume,size,depth)\n",
    "    #   add only black background mri image\n",
    "        if volume.shape[2]!=depth:\n",
    "            add_black_num = depth - volume.shape[2]\n",
    "            volume = np.transpose(volume)\n",
    "            for i in range(add_black_num):\n",
    "                add_black_ = np.expand_dims(np.zeros((volume.shape[2],volume.shape[2])),axis=0)\n",
    "                volume = np.concatenate((volume, add_black_), axis = 0)\n",
    "            volume = np.transpose(volume)\n",
    "        volume = np.transpose(volume)\n",
    "    except:\n",
    "        pass\n",
    "        print(path)\n",
    "        volume = image = np.zeros((192,192,24))\n",
    "    return volume\n",
    "def mask_scan(path):\n",
    "# get nib first channel\n",
    "    try:\n",
    "        image = nib.load(path)\n",
    "        if len(image.shape) == 4:\n",
    "            image = image.get_fdata()\n",
    "            width,height,queue,_ = image.shape\n",
    "            image = image[:,:,:,1]\n",
    "            image = np.reshape(image,(width,height,queue))\n",
    "        else:\n",
    "            image = image.get_fdata()\n",
    "            pass\n",
    "\n",
    "        image = resize_volume(image,size,depth)\n",
    "        shape = image.shape\n",
    "    #   add only black background mri image\n",
    "        if image.shape[2]!=depth:\n",
    "            add_black_num = depth - image.shape[2]\n",
    "            image = np.transpose(image)\n",
    "            for i in range(add_black_num):\n",
    "                add_black_ = np.expand_dims(np.zeros((image.shape[2],image.shape[2])),axis=0)\n",
    "                image = np.concatenate((image, add_black_), axis = 0)\n",
    "            image = np.transpose(image)\n",
    "        image = np.transpose(image)\n",
    "    except:\n",
    "        pass\n",
    "        image = np.zeros((192,192,24))\n",
    "        print(path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nii load\n",
    "from tqdm import tqdm\n",
    "# from utils.nii_load import *\n",
    "image_arr = np.array([process_scan(path) for path in tqdm(image_path)])\n",
    "masks_arr = np.array([mask_scan(path) for path in tqdm(masks_path)])\n",
    "# image_arr = np.array([process_scan(path) for path in image_path])\n",
    "# masks_arr = np.array([mask_scan(path) for path in masks_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_arr.shape, masks_arr.shape)\n",
    "print(np.max(image_arr), np.min(image_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{save_nii_path}image_arr',image_arr)\n",
    "np.save(f'{save_nii_path}masks_arr',masks_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nii array processing\n",
    "image_arr = np.load(f'{save_nii_path}image_arr.npy')\n",
    "masks_arr = np.load(f'{save_nii_path}masks_arr.npy')\n",
    "print(image_arr.shape, masks_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification extract image_seg area\n",
    "try:\n",
    "    image_mask_arr_t = np.zeros((image_arr_t.shape[0],32,192,192))\n",
    "    image_mask_arr_f = np.zeros((image_arr_f.shape[0],32,192,192))\n",
    "\n",
    "    def mask_stroke_area(image_, mask_):\n",
    "        image_save = image_.copy()\n",
    "        for i in range(image_.shape[0]):\n",
    "            for j in range(image_.shape[1]):\n",
    "                for k in range(image_.shape[2]):\n",
    "                    if mask_[i][j][k]==0:\n",
    "                        image_save[i][j][k]=0\n",
    "        return image_save\n",
    "\n",
    "    # for i in tqdm(range(cost)):\n",
    "    for i in tqdm(range(image_arr_t.shape[0])):\n",
    "        image_mask_arr_t[i] = mask_stroke_area(image_arr_t[i],masks_arr_t[i])\n",
    "\n",
    "    for i in tqdm(range(image_arr_f.shape[0])):\n",
    "        image_mask_arr_f[i] = mask_stroke_area(image_arr_f[i],masks_arr_f[i])\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification extract image_seg area save\n",
    "try:\n",
    "    np.save(f'{save_nii_path}image_mask_arr_t',image_mask_arr_t)\n",
    "    np.save(f'{save_nii_path}image_mask_arr_f',image_mask_arr_f)\n",
    "    image_mask_arr_t = np.load(f'{save_nii_path}image_mask_arr_t.npy')\n",
    "    image_mask_arr_f = np.load(f'{save_nii_path}image_mask_arr_f.npy')\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification label array\n",
    "try:\n",
    "    image_label_t = np.array([1. for _ in range(image_arr_t.shape[0])])\n",
    "    image_label_f = np.array([0. for _ in range(image_arr_f.shape[0])])\n",
    "    print(image_label_t.shape, image_label_f.shape)\n",
    "    print(image_label_t[0:5], image_label_f[0:5])\n",
    "    np.save(f'{save_nii_path}image_label_t',image_label_t)\n",
    "    np.save(f'{save_nii_path}image_label_f',image_label_f)\n",
    "    image_label_t = np.load(f'{save_nii_path}image_label_t.npy')\n",
    "    image_label_f = np.load(f'{save_nii_path}image_label_f.npy')\n",
    "    print(image_label_t.shape, image_label_f.shape)\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 3 shuffle data\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# random shuffle dataset\n",
    "def random_data_shuffle(data_arr):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_arr) #image\n",
    "    return data_arr\n",
    "# segmentation npy data processing\n",
    "\n",
    "try:\n",
    "    image_arr = random_data_shuffle(image_arr)\n",
    "    masks_arr = random_data_shuffle(masks_arr)\n",
    "except:\n",
    "    print('pass')\n",
    "    \n",
    "# Classification npy data processing\n",
    "try:\n",
    "    image_mask_arr_t = random_data_shuffle(image_mask_arr_t)\n",
    "    image_label_t = random_data_shuffle(image_label_t)\n",
    "    image_mask_arr_f = random_data_shuffle(image_mask_arr_f)\n",
    "    image_label_f = random_data_shuffle(image_label_f)\n",
    "except:\n",
    "    print('pass')\n",
    "    \n",
    "# path\n",
    "try:\n",
    "    img_path = random_data_shuffle(image_path)\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data size cv\n",
    "_size = int(image_arr.shape[0]*0.8)\n",
    "print(_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation npy data processing ,cv\n",
    "try:\n",
    "    sx_train = image_arr[:_size]\n",
    "    sy_train = masks_arr[:_size]\n",
    "    sx_val = image_arr[_size:]\n",
    "    sy_val = masks_arr[_size:]\n",
    "    print(sx_train.shape, sy_train.shape, sx_val.shape, sy_val.shape)\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification npy data processing ,cv\n",
    "try:\n",
    "    cx_train = np.concatenate((image_mask_arr_t[:t_size],image_mask_arr_f[:f_size]),axis=0)\n",
    "    cy_train = np.concatenate((image_label_t[:t_size], image_label_f[:f_size]), axis=0)\n",
    "\n",
    "    cx_val = np.concatenate((image_mask_arr_t[t_size:], image_mask_arr_f[f_size:]), axis=0)\n",
    "    cy_val = np.concatenate((image_label_t[t_size:], image_label_f[f_size:]), axis=0)\n",
    "\n",
    "    print(cx_train.shape, cy_train.shape, cx_val.shape, cy_val.shape)\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data name and data path ,cv\n",
    "try:\n",
    "    train_path = img_path[:_size]\n",
    "    valid_path = img_path[_size:]\n",
    "    train_val_path = np.concatenate((train_path,valid_path))\n",
    "    print(train_val_path[0])\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmentation npy data processing ,cv\n",
    "try:\n",
    "    strain_val_x = np.concatenate((sx_train,sx_val))\n",
    "    strain_val_y = np.concatenate((sy_train,sy_val))\n",
    "    print(strain_val_x.shape, strain_val_y.shape)\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification npy data processing ,cv\n",
    "try:\n",
    "    ctrain_val_x = np.concatenate((cx_train,cx_val))\n",
    "    ctrain_val_y = np.concatenate((cy_train,cy_val))\n",
    "    print(ctrain_val_x.shape, ctrain_val_y.shape)\n",
    "except:\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data name and data path ,cv\n",
    "cv = seed\n",
    "try:\n",
    "    np.save(save_nii_path+f'cv{cv}_path_train_val',train_val_path)\n",
    "    print(train_val_path.shape)\n",
    "except:\n",
    "    print('pass')\n",
    "# Save segmentation npy data processing ,cv\n",
    "try:\n",
    "    np.save(save_nii_path+f'cv{cv}_x_strain_val',strain_val_x)\n",
    "    np.save(save_nii_path+f'cv{cv}_y_strain_val',strain_val_y)\n",
    "    print(strain_val_x.shape,strain_val_y.shape)\n",
    "except:\n",
    "    print('pass')\n",
    "# Save classification npy data processing ,cv\n",
    "try:\n",
    "    np.save(save_nii_path+f'cv{cv}_x_ctrain_val',ctrain_val_x)\n",
    "    np.save(save_nii_path+f'cv{cv}_y_ctrain_val',ctrain_val_y)\n",
    "    print(ctrain_val_x.shape,ctrain_val_y.shape)\n",
    "except:\n",
    "    print('pass')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
