{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2817,
     "status": "ok",
     "timestamp": 1610349740483,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "uXA4lt-kQvlT"
   },
   "outputs": [],
   "source": [
    "import zipfile, os, cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "tf.executing_eagerly()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# Display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import nibabel as nib\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "MRI_nii_folder_path = 'nii_save_np/lacune/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4588,
     "status": "ok",
     "timestamp": 1610349742367,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "Lk_3Y94z1yhl"
   },
   "outputs": [],
   "source": [
    "seed = 3\n",
    "# seed: cv1=1 cv2=2 cv3=3 cv4=4 cv5=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7790,
     "status": "ok",
     "timestamp": 1610349745612,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "PEPA2nt1ywth",
    "outputId": "8a93f992-1861-48b5-9242-f2d33413288f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 32, 192, 192) (129,) (129,)\n"
     ]
    }
   ],
   "source": [
    "cv = seed\n",
    "train_val_x = np.load(MRI_nii_folder_path+f'cv{cv}_x_ctrain_val.npy')\n",
    "train_val_y = np.load(MRI_nii_folder_path+f'cv{cv}_y_ctrain_val.npy')\n",
    "train_val_path = np.load(MRI_nii_folder_path+f'cv{cv}_path_train_val.npy')\n",
    "print(train_val_x.shape,train_val_y.shape,train_val_path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "print(int(train_val_x.shape[0]*0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7781,
     "status": "ok",
     "timestamp": 1610349745613,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "f24QzBfx16za"
   },
   "outputs": [],
   "source": [
    "x_train = train_val_x[:103]\n",
    "y_train = train_val_y[:103]\n",
    "x_val = train_val_x[103:]\n",
    "y_val = train_val_y[103:]\n",
    "train_path = train_val_path[:103]\n",
    "valid_path = train_val_path[103:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7773,
     "status": "ok",
     "timestamp": 1610349745614,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "yqVpDnP9w_Ph",
    "outputId": "82d49741-d319-48f1-a2ea-36742419d464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 32, 192, 192)\n",
      "(103,)\n",
      "(26, 32, 192, 192)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(103,)\n",
      "(26,)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "imgs_train = x_train.astype(np.float32)\n",
    "imgs_valid = x_val.astype(np.float32)\n",
    "# imgs_label_train = to_categorical(y_train, 2)\n",
    "# imgs_label_valid = to_categorical(y_val, 2)\n",
    "imgs_label_train = y_train.astype(int)\n",
    "imgs_label_valid = y_val.astype(int)\n",
    "print(imgs_train.shape)\n",
    "print(imgs_label_train.shape)\n",
    "print(imgs_valid.shape)\n",
    "print(imgs_label_valid)\n",
    "print(train_path.shape)\n",
    "print(valid_path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moderate-severe = 0:0.8583333333333333, mild = 1:1.197674418604651\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439 1.19767439\n",
      " 1.19767439 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335 0.85833335\n",
      " 0.85833335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/er_tf2/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes=[0,1]\n",
    "cw = compute_class_weight('balanced', classes, y_train)\n",
    "print(f\"moderate-severe = 0:{cw[0]}, mild = 1:{cw[1]}\")\n",
    "# print(cw)\n",
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 0] = cw[0].astype(np.float32)\n",
    "sample_weight[y_train == 1] = cw[1].astype(np.float32)\n",
    "# print(y_train)\n",
    "# print(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel max = 1 pixel min = 0\n",
      "pixel max = 6.0720720291137695 pixel min = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAACFCAYAAAAD6h5CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKiUlEQVR4nO3dT2td5drA4Xt176QJJjEJhkYkGFKUUm0DaTVgpB2IiKKI4sCBONCBoAh+gILfwa8gDtSRSKGoE1u0FqERBf9RNNUYxTRJm3Zn59/e6wzkDbwcGk+XJ2c9WbkuyKDdsLkJT+80P9baK8vzPAAAAAAo376yBwAAAADgL0INAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkor7di1mWeXZ3ReV5nu3k+zs71bWTZ8e5qS47h6LsHIqwcyjKzqEI54Yitjs3rqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAA8G8OHjwYR48ejXq9XvYoe4rvNgAAALAly7IYHx+P119/PXp7e+OVV16JpaWlssfaM4QaAACACsuyLPI8L3sMdpF77703Tp06FRMTE7G2thYdHR1lj7SnuPUJAACggur1ejz88MPx8ssvx3333Vf2OOwS3d3d8dJLL8XJkycjImJpaSna7XbJU+0trqgBAACooP7+/rj//vtjZGQk7r777vjxxx+jXq/HuXPnYmZmJjY3N8sekQQdO3Ysnn766ejs7Izr169Hs9mMF154Ic6cORPff/992ePtCUINAABARXR2dsYdd9wRc3Nz0dXVFSMjIzE2NhZ33nlnTE1NRavViqmpqfjkk0/igw8+iGazWfbIJGb//v2xvr4e8/PzcePGjcjzPJ588sk4ePBgvPHGG9FqtcoesfKEGgAAgIo4cOBAvPjii3Hu3LmYnZ2N4eHhGB4ejrvuuisGBwej3W5Hf39/tFqtOHv2rFDDv7l8+XL8+eefcfvtt0ej0YjV1dUYGBiIQ4cOxRNPPBHnz5+PK1eulD1mpfmMGgAAgArIsiwmJiZifHw8pqamorOzMzY3N6PdbsfGxkZsbGxEb29vHDp0KB588MF45JFHyh6ZBK2vr8fc3Fw0Go1YWVmJ69evR6PRiKGhoXjttdfizTffjIMHD0aWZWWPWllCDQAAQAXUarWYnJyMLMtidHQ0Njc3Y2ZmJhqNRiwtLcUff/wR8/PzERExODgYx44dK3liUnT9+vW4dOlStFqtraeFzc/Px5UrV+LAgQNx/PjxOHXqVDz//PPR09NT8rTV5NYnAACACsiyLDo6OmJ9fT3W19djcXExvv322zhy5EhkWRZra2vRbrej2WzGwsJCzM3NlT0yCVpaWooLFy7E8ePHo16vR61Wi9XV1fj999+j3W5HX19fPPTQQzE6Ohq1Wi3eeecdj3//LxNqAAAAKqDVasXFixcjz/M4ffp0NBqNuHr1aty4cSOyLIuVlZVoNptRq9Xi2rVr8d5775U9Mon69NNP4/HHH4+JiYmtv1tdXY3l5eXI8zyyLIuurq7Y3NwUaXaAUAMAAFAB7XY7zp8/H19++WVcunQpIiK++uqrOHHiRIyMjES9Xo/l5eXIsiyazWasr6+XPDGpWltbi9OnT8eRI0dieHg4VlZW4urVq9FqtWJ9fT1mZ2cjIuKbb74pedJqEmoAAAAqYmZm5v/9eWVlJX7++efo7Ozc+oU7y7JYWFiIjY2NcoYkeXmex8WLF+OLL76Io0ePRkdHR/T09MTq6mpExNajuxuNRsmTVpNQAwAAUFEbGxvx7rvvxgMPPBCTk5MxPDwczWZz6+oIuJmFhYX46KOPYmVlJYaGhmJoaCj6+vqio6MjLly4EO+//36srKyUPWYlCTUAAAAVtrGxEZ9//nl899138dxzz8UPP/wQo6Oj0W63yx6NxH322Wdx6dKl6OjoiBMnTsQzzzwTXV1dcfjw4Wi3287QDhFqAAAA9oClpaWYnp6OxcXFWF1d9Us2f2tzczN+++23iIhYXFyMp556KvI8j59++slnHO0goQYAAGCPmJ6ejoiIy5cvCzXckv97ulN3d3f8+uuvsbm5WfJE1bWv7AEAAAD432i1WltfHqvMrWi327G8vByDg4NRq9XKHqfShBoAAABgW41GI95+++1YW1uLet3NOTtJqAEAAAD+1szMTHz88cdxzz33RGdnZ9njVJZQAwAAAPytmZmZeOutt+LatWuRZVnZ41RWtt19iVmWuWmxovI839F/Vc5Ode3k2XFuqsvOoSg7hyLsHIqycyhir52bffv2xf79+6PZbJY9yq623blxRQ0AAADwH2m32yLNDhNqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAIBECDUAAAAAiRBqAAAAABIh1AAAAAAkQqgBAAAASIRQAwAAAJAIoQYAAAAgEUINAAAAQCKEGgAAAGDLY489FidPnix7jD2rXvYAAAAAQDoOHz4cCwsLZY+xZwk1AAAAwJavv/46brvttrLH2LOyPM9v/mKW3fxFdrU8z7OdfH9np7p28uw4N9Vl51CUnUMRdg5F2TkUUcVzs2/fvhgYGHBVzQ7a7tz4jBoAAABgS7vdFmlKJNQAAAAAJEKoAQAAAEiEUAMAAACQCKEGAAAAIBFCDQAAAEAihBoAAACARAg1AAAAwD9Wr9fLHqEShBoAAADgHxkbG4tHH3207DEqQe4CAAAA/pHx8fHo6+sre4xKEGoAAACAwnp7e2Nubi6mp6fLHqUSsjzPb/5ilt38RXa1PM+znXx/Z6e6dvLsODfVZedQlJ1DEXYORdk5FLGXz029Xo/R0dGYnZ2NjY2NaLVaZY+0a2x3bnxGDQAAAHDLBgYG4tVXX43+/n6R5r9IqAEAAABu2eTkZNRqtdjuTh1unVuf9iiXBFPUXr60k+LsHIqycyjCzqEoO4ci9vK56enpie7u7lhcXHRFzS3a7twINXuU/8BQ1F7+QURxdg5F2TkUYedQlJ1DEc7NX2q1WtTrfz2vaG1treRp0uczagAAAIAd8+yzz8aHH34YZ86cibGxsbLH2dU8nhsAAAD4R86ePRu//PJLdHd3R7PZLHucXc2tT3uUS4IpyqWdFGHnUJSdQxF2DkXZORTh3FCEW58AAAAAdgGhBgAAACARQg0AAABAIoQaAAAAgEQINQAAAACJEGoAAAAAEiHUAAAAACRCqAEAAABIhFADAAAAkAihBgAAACARQg0AAABAIoQaAAAAgEQINQAAAACJEGoAAAAAEiHUAAAAACQiy/O87BkAAAAACFfUAAAAACRDqAEAAABIhFADAAAAkAihBgAAACARQg0AAABAIoQaAAAAgET8C26tRv3OkoKuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x1440 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "mask_arr_ = imgs_train[50]\n",
    "print(f\"pixel max = {np.max(imgs_label_valid)} pixel min = {np.min(imgs_label_valid)}\")\n",
    "print(f\"pixel max = {np.max(imgs_train)} pixel min = {np.min(imgs_train)}\")\n",
    "for i in range(mask_arr_.shape[0]-24):\n",
    "    plt.subplot(1,mask_arr_.shape[0]-24,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mask_arr_[i],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7765,
     "status": "ok",
     "timestamp": 1610349745615,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "oclGgc-px6JC"
   },
   "outputs": [],
   "source": [
    "from utils.processing_data import train_preprocessing, validation_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8469,
     "status": "ok",
     "timestamp": 1610349746326,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "YuZxpiEu0kBk"
   },
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((imgs_train, imgs_label_train, sample_weight))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((imgs_valid, imgs_label_valid))\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 8464,
     "status": "ok",
     "timestamp": 1610349746327,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "BJhr1S8t2hCO"
   },
   "outputs": [],
   "source": [
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "#     .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "#     .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8732,
     "status": "ok",
     "timestamp": 1610349746603,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "TmJYpykn2qlo",
    "outputId": "c9c0cdef-8af4-4345-a7c6-bbb5a37b27f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30, 95, 95, 64)\n",
      "(None, 14, 46, 93, 64)\n",
      "(None, 6, 22, 91, 128)\n",
      "(None, 2, 10, 89, 256)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from utils.model_1 import get_model\n",
    "model = get_model(depth=32, width=192, height=192, class_num=1, classification_layer='sigmoid')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8719,
     "status": "ok",
     "timestamp": 1610349746603,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "ukum2JHC68BS"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def binary_focal_loss(gamma=2, alpha=0.25):\n",
    "\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true*alpha + (K.ones_like(y_true)-y_true)*(1-alpha)\n",
    "    \n",
    "        p_t = y_true*y_pred + (K.ones_like(y_true)-y_true)*(K.ones_like(y_true)-y_pred) + K.epsilon()\n",
    "        focal_loss = - alpha_t * K.pow((K.ones_like(y_true)-p_t),gamma) * K.log(p_t)\n",
    "        return K.mean(focal_loss)\n",
    "    return binary_focal_loss_fixed\n",
    "focal_loss = binary_focal_loss(gamma=2, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 9047,
     "status": "ok",
     "timestamp": 1610349746938,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "wnVKS3KG3Emq"
   },
   "outputs": [],
   "source": [
    "import datetime, keras.callbacks\n",
    "initial_learning_rate = 1e-5\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    # loss=\"binary_crossentropy\",\n",
    "    loss=focal_loss,\n",
    "    optimizer=keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='acc')\n",
    "             ,tf.keras.metrics.AUC(name = 'auc')\n",
    "             ,tf.keras.metrics.Recall(name = 'rec')\n",
    "            ],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "save_path ='chekpoint/lacune/'\n",
    "checkpoint_name = f\"154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv{cv}_t1_cw\"\n",
    "tlogdir = os.path.join(\"chekpoint/logs_lacune/\", checkpoint_name)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tlogdir,histogram_freq=1)\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    f\"{save_path}{checkpoint_name}.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True\n",
    ")\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=30)\n",
    "reduceLR_cb = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=15, \n",
    "                                                factor=0.1, verbose=1, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n"
     ]
    }
   ],
   "source": [
    "weight_path=save_path+checkpoint_name+'.h5'\n",
    "print(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3678099,
     "status": "ok",
     "timestamp": 1610353416008,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "e7bBYi4O6877",
    "outputId": "58b01e6b-8ef4-47a1-c9bb-601c426e636a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0783 - acc: 0.7379 - auc: 0.8213 - rec: 0.8605\n",
      "Epoch 00001: val_acc improved from -inf to 0.42308, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 23s 870ms/step - loss: 0.0783 - acc: 0.7379 - auc: 0.8213 - rec: 0.8605 - val_loss: 0.0984 - val_acc: 0.4231 - val_auc: 0.6212 - val_rec: 1.0000\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0710 - acc: 0.7573 - auc: 0.8277 - rec: 0.8605\n",
      "Epoch 00002: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 20s 788ms/step - loss: 0.0710 - acc: 0.7573 - auc: 0.8277 - rec: 0.8605 - val_loss: 0.1020 - val_acc: 0.4231 - val_auc: 0.5000 - val_rec: 1.0000\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0713 - acc: 0.6602 - auc: 0.7488 - rec: 0.6512\n",
      "Epoch 00003: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 20s 775ms/step - loss: 0.0713 - acc: 0.6602 - auc: 0.7488 - rec: 0.6512 - val_loss: 0.1039 - val_acc: 0.4231 - val_auc: 0.5000 - val_rec: 1.0000\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0622 - acc: 0.7961 - auc: 0.8812 - rec: 0.8372\n",
      "Epoch 00004: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0622 - acc: 0.7961 - auc: 0.8812 - rec: 0.8372 - val_loss: 0.1053 - val_acc: 0.4231 - val_auc: 0.4121 - val_rec: 1.0000\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0584 - acc: 0.7670 - auc: 0.8508 - rec: 0.7209\n",
      "Epoch 00005: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 796ms/step - loss: 0.0584 - acc: 0.7670 - auc: 0.8508 - rec: 0.7209 - val_loss: 0.1102 - val_acc: 0.4231 - val_auc: 0.4667 - val_rec: 1.0000\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.8058 - auc: 0.8374 - rec: 0.7674\n",
      "Epoch 00006: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 22s 830ms/step - loss: 0.0606 - acc: 0.8058 - auc: 0.8374 - rec: 0.7674 - val_loss: 0.1086 - val_acc: 0.4231 - val_auc: 0.5333 - val_rec: 1.0000\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0581 - acc: 0.6990 - auc: 0.8359 - rec: 0.6047\n",
      "Epoch 00007: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 20s 784ms/step - loss: 0.0581 - acc: 0.6990 - auc: 0.8359 - rec: 0.6047 - val_loss: 0.1062 - val_acc: 0.4231 - val_auc: 0.4091 - val_rec: 1.0000\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0539 - acc: 0.7767 - auc: 0.8975 - rec: 0.6512\n",
      "Epoch 00008: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 0.0539 - acc: 0.7767 - auc: 0.8975 - rec: 0.6512 - val_loss: 0.1026 - val_acc: 0.4231 - val_auc: 0.4727 - val_rec: 1.0000\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.7087 - auc: 0.8234 - rec: 0.5349\n",
      "Epoch 00009: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 813ms/step - loss: 0.0605 - acc: 0.7087 - auc: 0.8234 - rec: 0.5349 - val_loss: 0.1041 - val_acc: 0.4231 - val_auc: 0.3727 - val_rec: 1.0000\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0570 - acc: 0.6990 - auc: 0.8304 - rec: 0.4419\n",
      "Epoch 00010: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 815ms/step - loss: 0.0570 - acc: 0.6990 - auc: 0.8304 - rec: 0.4419 - val_loss: 0.1028 - val_acc: 0.4231 - val_auc: 0.3515 - val_rec: 1.0000\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0524 - acc: 0.7767 - auc: 0.8839 - rec: 0.6047\n",
      "Epoch 00011: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 815ms/step - loss: 0.0524 - acc: 0.7767 - auc: 0.8839 - rec: 0.6047 - val_loss: 0.1112 - val_acc: 0.4231 - val_auc: 0.4242 - val_rec: 1.0000\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0543 - acc: 0.6990 - auc: 0.8459 - rec: 0.4651\n",
      "Epoch 00012: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 812ms/step - loss: 0.0543 - acc: 0.6990 - auc: 0.8459 - rec: 0.4651 - val_loss: 0.1207 - val_acc: 0.4231 - val_auc: 0.5091 - val_rec: 1.0000\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0535 - acc: 0.7184 - auc: 0.8483 - rec: 0.6279\n",
      "Epoch 00013: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 21s 793ms/step - loss: 0.0535 - acc: 0.7184 - auc: 0.8483 - rec: 0.6279 - val_loss: 0.1137 - val_acc: 0.4231 - val_auc: 0.4515 - val_rec: 1.0000\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0550 - acc: 0.6796 - auc: 0.8300 - rec: 0.4884\n",
      "Epoch 00014: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 22s 827ms/step - loss: 0.0550 - acc: 0.6796 - auc: 0.8300 - rec: 0.4884 - val_loss: 0.1149 - val_acc: 0.4231 - val_auc: 0.5061 - val_rec: 1.0000\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0510 - acc: 0.7864 - auc: 0.8971 - rec: 0.6047\n",
      "Epoch 00015: val_acc did not improve from 0.42308\n",
      "26/26 [==============================] - 22s 833ms/step - loss: 0.0510 - acc: 0.7864 - auc: 0.8971 - rec: 0.6047 - val_loss: 0.1242 - val_acc: 0.4231 - val_auc: 0.7788 - val_rec: 1.0000\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.7864 - auc: 0.8860 - rec: 0.6744\n",
      "Epoch 00016: val_acc improved from 0.42308 to 0.46154, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 20s 782ms/step - loss: 0.0477 - acc: 0.7864 - auc: 0.8860 - rec: 0.6744 - val_loss: 0.1184 - val_acc: 0.4615 - val_auc: 0.6939 - val_rec: 1.0000\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0515 - acc: 0.7476 - auc: 0.8630 - rec: 0.5581\n",
      "Epoch 00017: val_acc did not improve from 0.46154\n",
      "26/26 [==============================] - 21s 808ms/step - loss: 0.0515 - acc: 0.7476 - auc: 0.8630 - rec: 0.5581 - val_loss: 0.1161 - val_acc: 0.4615 - val_auc: 0.7939 - val_rec: 0.9091\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0510 - acc: 0.7961 - auc: 0.8901 - rec: 0.6977\n",
      "Epoch 00018: val_acc improved from 0.46154 to 0.53846, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 21s 791ms/step - loss: 0.0510 - acc: 0.7961 - auc: 0.8901 - rec: 0.6977 - val_loss: 0.1020 - val_acc: 0.5385 - val_auc: 0.7242 - val_rec: 0.9091\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.7767 - auc: 0.8953 - rec: 0.5814\n",
      "Epoch 00019: val_acc improved from 0.53846 to 0.57692, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 21s 821ms/step - loss: 0.0472 - acc: 0.7767 - auc: 0.8953 - rec: 0.5814 - val_loss: 0.0970 - val_acc: 0.5769 - val_auc: 0.7909 - val_rec: 0.9091\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0514 - acc: 0.7670 - auc: 0.8601 - rec: 0.6279\n",
      "Epoch 00020: val_acc did not improve from 0.57692\n",
      "26/26 [==============================] - 22s 847ms/step - loss: 0.0514 - acc: 0.7670 - auc: 0.8601 - rec: 0.6279 - val_loss: 0.0963 - val_acc: 0.5769 - val_auc: 0.8576 - val_rec: 0.9091\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.7961 - auc: 0.8874 - rec: 0.6047\n",
      "Epoch 00021: val_acc improved from 0.57692 to 0.61538, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 22s 855ms/step - loss: 0.0483 - acc: 0.7961 - auc: 0.8874 - rec: 0.6047 - val_loss: 0.0898 - val_acc: 0.6154 - val_auc: 0.8424 - val_rec: 0.9091\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0479 - acc: 0.7864 - auc: 0.8833 - rec: 0.6047\n",
      "Epoch 00022: val_acc improved from 0.61538 to 0.69231, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 21s 810ms/step - loss: 0.0479 - acc: 0.7864 - auc: 0.8833 - rec: 0.6047 - val_loss: 0.0866 - val_acc: 0.6923 - val_auc: 0.8606 - val_rec: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.7087 - auc: 0.8269 - rec: 0.4651\n",
      "Epoch 00023: val_acc improved from 0.69231 to 0.76923, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 21s 790ms/step - loss: 0.0548 - acc: 0.7087 - auc: 0.8269 - rec: 0.4651 - val_loss: 0.0784 - val_acc: 0.7692 - val_auc: 0.8091 - val_rec: 0.8182\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.7379 - auc: 0.8828 - rec: 0.5581\n",
      "Epoch 00024: val_acc did not improve from 0.76923\n",
      "26/26 [==============================] - 22s 827ms/step - loss: 0.0470 - acc: 0.7379 - auc: 0.8828 - rec: 0.5581 - val_loss: 0.0789 - val_acc: 0.7692 - val_auc: 0.8727 - val_rec: 0.8182\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.8155 - auc: 0.8940 - rec: 0.6744\n",
      "Epoch 00025: val_acc did not improve from 0.76923\n",
      "26/26 [==============================] - 21s 799ms/step - loss: 0.0483 - acc: 0.8155 - auc: 0.8940 - rec: 0.6744 - val_loss: 0.0760 - val_acc: 0.7692 - val_auc: 0.8545 - val_rec: 0.7273\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0504 - acc: 0.7476 - auc: 0.8667 - rec: 0.5116\n",
      "Epoch 00026: val_acc did not improve from 0.76923\n",
      "26/26 [==============================] - 21s 801ms/step - loss: 0.0504 - acc: 0.7476 - auc: 0.8667 - rec: 0.5116 - val_loss: 0.0766 - val_acc: 0.7692 - val_auc: 0.8545 - val_rec: 0.5455\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0503 - acc: 0.7282 - auc: 0.8531 - rec: 0.4884\n",
      "Epoch 00027: val_acc improved from 0.76923 to 0.84615, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 21s 805ms/step - loss: 0.0503 - acc: 0.7282 - auc: 0.8531 - rec: 0.4884 - val_loss: 0.0781 - val_acc: 0.8462 - val_auc: 0.8818 - val_rec: 0.7273\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.7670 - auc: 0.8901 - rec: 0.6047\n",
      "Epoch 00028: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 817ms/step - loss: 0.0465 - acc: 0.7670 - auc: 0.8901 - rec: 0.6047 - val_loss: 0.0828 - val_acc: 0.8077 - val_auc: 0.8788 - val_rec: 0.7273\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0464 - acc: 0.7767 - auc: 0.8876 - rec: 0.6744\n",
      "Epoch 00029: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 807ms/step - loss: 0.0464 - acc: 0.7767 - auc: 0.8876 - rec: 0.6744 - val_loss: 0.0826 - val_acc: 0.8077 - val_auc: 0.8818 - val_rec: 0.5455\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0514 - acc: 0.7670 - auc: 0.8548 - rec: 0.6047\n",
      "Epoch 00030: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 809ms/step - loss: 0.0514 - acc: 0.7670 - auc: 0.8548 - rec: 0.6047 - val_loss: 0.0816 - val_acc: 0.7692 - val_auc: 0.8818 - val_rec: 0.4545\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0520 - acc: 0.7379 - auc: 0.8566 - rec: 0.5349\n",
      "Epoch 00031: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 0.0520 - acc: 0.7379 - auc: 0.8566 - rec: 0.5349 - val_loss: 0.0796 - val_acc: 0.5769 - val_auc: 0.8879 - val_rec: 0.0000e+00\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0478 - acc: 0.7184 - auc: 0.8700 - rec: 0.4419\n",
      "Epoch 00032: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 813ms/step - loss: 0.0478 - acc: 0.7184 - auc: 0.8700 - rec: 0.4419 - val_loss: 0.0807 - val_acc: 0.5769 - val_auc: 0.8909 - val_rec: 0.0000e+00\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0383 - acc: 0.8447 - auc: 0.9477 - rec: 0.6744\n",
      "Epoch 00033: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 775ms/step - loss: 0.0383 - acc: 0.8447 - auc: 0.9477 - rec: 0.6744 - val_loss: 0.0853 - val_acc: 0.6923 - val_auc: 0.8909 - val_rec: 0.2727\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0498 - acc: 0.7282 - auc: 0.8579 - rec: 0.4419\n",
      "Epoch 00034: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 777ms/step - loss: 0.0498 - acc: 0.7282 - auc: 0.8579 - rec: 0.4419 - val_loss: 0.0903 - val_acc: 0.6923 - val_auc: 0.8848 - val_rec: 0.2727\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.7961 - auc: 0.8903 - rec: 0.6512\n",
      "Epoch 00035: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 771ms/step - loss: 0.0487 - acc: 0.7961 - auc: 0.8903 - rec: 0.6512 - val_loss: 0.0930 - val_acc: 0.7308 - val_auc: 0.8848 - val_rec: 0.3636\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0398 - acc: 0.8058 - auc: 0.9256 - rec: 0.6977\n",
      "Epoch 00036: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 782ms/step - loss: 0.0398 - acc: 0.8058 - auc: 0.9256 - rec: 0.6977 - val_loss: 0.0936 - val_acc: 0.6923 - val_auc: 0.8909 - val_rec: 0.2727\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0475 - acc: 0.8252 - auc: 0.8866 - rec: 0.7209\n",
      "Epoch 00037: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 792ms/step - loss: 0.0475 - acc: 0.8252 - auc: 0.8866 - rec: 0.7209 - val_loss: 0.0954 - val_acc: 0.7308 - val_auc: 0.8848 - val_rec: 0.3636\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.7573 - auc: 0.8969 - rec: 0.5581\n",
      "Epoch 00038: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0439 - acc: 0.7573 - auc: 0.8969 - rec: 0.5581 - val_loss: 0.0965 - val_acc: 0.6923 - val_auc: 0.8848 - val_rec: 0.2727\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0475 - acc: 0.7961 - auc: 0.9058 - rec: 0.6279\n",
      "Epoch 00039: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 782ms/step - loss: 0.0475 - acc: 0.7961 - auc: 0.9058 - rec: 0.6279 - val_loss: 0.0943 - val_acc: 0.5769 - val_auc: 0.8879 - val_rec: 0.0000e+00\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.7767 - auc: 0.8829 - rec: 0.6047\n",
      "Epoch 00040: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 779ms/step - loss: 0.0471 - acc: 0.7767 - auc: 0.8829 - rec: 0.6047 - val_loss: 0.0973 - val_acc: 0.5769 - val_auc: 0.8879 - val_rec: 0.0000e+00\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.8155 - auc: 0.9198 - rec: 0.6744\n",
      "Epoch 00041: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 780ms/step - loss: 0.0417 - acc: 0.8155 - auc: 0.9198 - rec: 0.6744 - val_loss: 0.0979 - val_acc: 0.5769 - val_auc: 0.8909 - val_rec: 0.0000e+00\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0383 - acc: 0.8350 - auc: 0.9440 - rec: 0.6744\n",
      "Epoch 00042: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 777ms/step - loss: 0.0383 - acc: 0.8350 - auc: 0.9440 - rec: 0.6744 - val_loss: 0.1007 - val_acc: 0.5769 - val_auc: 0.8848 - val_rec: 0.0000e+00\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.7961 - auc: 0.9120 - rec: 0.6512\n",
      "Epoch 00043: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 775ms/step - loss: 0.0417 - acc: 0.7961 - auc: 0.9120 - rec: 0.6512 - val_loss: 0.1051 - val_acc: 0.6923 - val_auc: 0.8879 - val_rec: 0.2727\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0408 - acc: 0.7767 - auc: 0.9215 - rec: 0.6047\n",
      "Epoch 00044: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 764ms/step - loss: 0.0408 - acc: 0.7767 - auc: 0.9215 - rec: 0.6047 - val_loss: 0.1069 - val_acc: 0.6538 - val_auc: 0.8939 - val_rec: 0.1818\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0420 - acc: 0.7767 - auc: 0.9083 - rec: 0.6047\n",
      "Epoch 00045: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 780ms/step - loss: 0.0420 - acc: 0.7767 - auc: 0.9083 - rec: 0.6047 - val_loss: 0.1066 - val_acc: 0.6923 - val_auc: 0.8939 - val_rec: 0.2727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.7670 - auc: 0.9031 - rec: 0.6047\n",
      "Epoch 00046: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 778ms/step - loss: 0.0412 - acc: 0.7670 - auc: 0.9031 - rec: 0.6047 - val_loss: 0.1055 - val_acc: 0.6923 - val_auc: 0.8939 - val_rec: 0.2727\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0452 - acc: 0.7476 - auc: 0.8700 - rec: 0.6047\n",
      "Epoch 00047: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 785ms/step - loss: 0.0452 - acc: 0.7476 - auc: 0.8700 - rec: 0.6047 - val_loss: 0.1070 - val_acc: 0.6538 - val_auc: 0.8909 - val_rec: 0.1818\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.7767 - auc: 0.9070 - rec: 0.5814\n",
      "Epoch 00048: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 790ms/step - loss: 0.0418 - acc: 0.7767 - auc: 0.9070 - rec: 0.5814 - val_loss: 0.1081 - val_acc: 0.5769 - val_auc: 0.8848 - val_rec: 0.0000e+00\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.8155 - auc: 0.9318 - rec: 0.6512\n",
      "Epoch 00049: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 0.0403 - acc: 0.8155 - auc: 0.9318 - rec: 0.6512 - val_loss: 0.1089 - val_acc: 0.7308 - val_auc: 0.8939 - val_rec: 0.3636\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0476 - acc: 0.8058 - auc: 0.8859 - rec: 0.6744\n",
      "Epoch 00050: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 811ms/step - loss: 0.0476 - acc: 0.8058 - auc: 0.8859 - rec: 0.6744 - val_loss: 0.1072 - val_acc: 0.7308 - val_auc: 0.8909 - val_rec: 0.3636\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0389 - acc: 0.8252 - auc: 0.9192 - rec: 0.6977\n",
      "Epoch 00051: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 22s 832ms/step - loss: 0.0389 - acc: 0.8252 - auc: 0.9192 - rec: 0.6977 - val_loss: 0.1144 - val_acc: 0.5769 - val_auc: 0.8848 - val_rec: 0.0000e+00\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.7184 - auc: 0.8477 - rec: 0.4884\n",
      "Epoch 00052: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 22s 842ms/step - loss: 0.0508 - acc: 0.7184 - auc: 0.8477 - rec: 0.4884 - val_loss: 0.1104 - val_acc: 0.5769 - val_auc: 0.8879 - val_rec: 0.0000e+00\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.8738 - auc: 0.9248 - rec: 0.7907\n",
      "Epoch 00053: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 803ms/step - loss: 0.0403 - acc: 0.8738 - auc: 0.9248 - rec: 0.7907 - val_loss: 0.1100 - val_acc: 0.5769 - val_auc: 0.8818 - val_rec: 0.0000e+00\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.7379 - auc: 0.8539 - rec: 0.5349\n",
      "Epoch 00054: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 817ms/step - loss: 0.0487 - acc: 0.7379 - auc: 0.8539 - rec: 0.5349 - val_loss: 0.1089 - val_acc: 0.6923 - val_auc: 0.8879 - val_rec: 0.2727\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0419 - acc: 0.7864 - auc: 0.9066 - rec: 0.6279\n",
      "Epoch 00055: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 784ms/step - loss: 0.0419 - acc: 0.7864 - auc: 0.9066 - rec: 0.6279 - val_loss: 0.1090 - val_acc: 0.6154 - val_auc: 0.8848 - val_rec: 0.0909\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.8058 - auc: 0.9298 - rec: 0.6047\n",
      "Epoch 00056: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 0.0384 - acc: 0.8058 - auc: 0.9298 - rec: 0.6047 - val_loss: 0.1090 - val_acc: 0.7308 - val_auc: 0.8818 - val_rec: 0.3636\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0411 - acc: 0.7961 - auc: 0.9043 - rec: 0.6047\n",
      "Epoch 00057: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 797ms/step - loss: 0.0411 - acc: 0.7961 - auc: 0.9043 - rec: 0.6047 - val_loss: 0.1075 - val_acc: 0.7308 - val_auc: 0.8848 - val_rec: 0.3636\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0469 - acc: 0.7961 - auc: 0.9023 - rec: 0.6744\n",
      "Epoch 00058: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 791ms/step - loss: 0.0469 - acc: 0.7961 - auc: 0.9023 - rec: 0.6744 - val_loss: 0.1093 - val_acc: 0.5769 - val_auc: 0.8818 - val_rec: 0.0000e+00\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0390 - acc: 0.7961 - auc: 0.9246 - rec: 0.6047\n",
      "Epoch 00059: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 785ms/step - loss: 0.0390 - acc: 0.7961 - auc: 0.9246 - rec: 0.6047 - val_loss: 0.1053 - val_acc: 0.7308 - val_auc: 0.8818 - val_rec: 0.3636\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0423 - acc: 0.7864 - auc: 0.8971 - rec: 0.6512\n",
      "Epoch 00060: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 806ms/step - loss: 0.0423 - acc: 0.7864 - auc: 0.8971 - rec: 0.6512 - val_loss: 0.1073 - val_acc: 0.7308 - val_auc: 0.8818 - val_rec: 0.3636\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.8350 - auc: 0.9192 - rec: 0.6744\n",
      "Epoch 00061: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 803ms/step - loss: 0.0413 - acc: 0.8350 - auc: 0.9192 - rec: 0.6744 - val_loss: 0.1111 - val_acc: 0.6923 - val_auc: 0.8848 - val_rec: 0.2727\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.7864 - auc: 0.8955 - rec: 0.6279\n",
      "Epoch 00062: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 808ms/step - loss: 0.0439 - acc: 0.7864 - auc: 0.8955 - rec: 0.6279 - val_loss: 0.1120 - val_acc: 0.5769 - val_auc: 0.8818 - val_rec: 0.0000e+00\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.7961 - auc: 0.9103 - rec: 0.6279\n",
      "Epoch 00063: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 22s 828ms/step - loss: 0.0424 - acc: 0.7961 - auc: 0.9103 - rec: 0.6279 - val_loss: 0.1085 - val_acc: 0.5769 - val_auc: 0.8758 - val_rec: 0.0000e+00\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0355 - acc: 0.8058 - auc: 0.9465 - rec: 0.6279\n",
      "Epoch 00064: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 794ms/step - loss: 0.0355 - acc: 0.8058 - auc: 0.9465 - rec: 0.6279 - val_loss: 0.1071 - val_acc: 0.7308 - val_auc: 0.8818 - val_rec: 0.3636\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.8155 - auc: 0.9248 - rec: 0.6279\n",
      "Epoch 00065: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 776ms/step - loss: 0.0385 - acc: 0.8155 - auc: 0.9248 - rec: 0.6279 - val_loss: 0.1061 - val_acc: 0.7308 - val_auc: 0.8818 - val_rec: 0.3636\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.7961 - auc: 0.8785 - rec: 0.7442\n",
      "Epoch 00066: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 781ms/step - loss: 0.0501 - acc: 0.7961 - auc: 0.8785 - rec: 0.7442 - val_loss: 0.1100 - val_acc: 0.5769 - val_auc: 0.8818 - val_rec: 0.0000e+00\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.8544 - auc: 0.9469 - rec: 0.7674\n",
      "Epoch 00067: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 815ms/step - loss: 0.0344 - acc: 0.8544 - auc: 0.9469 - rec: 0.7674 - val_loss: 0.1043 - val_acc: 0.6923 - val_auc: 0.8758 - val_rec: 0.2727\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.8350 - auc: 0.9624 - rec: 0.6977\n",
      "Epoch 00068: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 814ms/step - loss: 0.0344 - acc: 0.8350 - auc: 0.9624 - rec: 0.6977 - val_loss: 0.1068 - val_acc: 0.7308 - val_auc: 0.8848 - val_rec: 0.3636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0394 - acc: 0.7670 - auc: 0.9151 - rec: 0.6279\n",
      "Epoch 00069: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 783ms/step - loss: 0.0394 - acc: 0.7670 - auc: 0.9151 - rec: 0.6279 - val_loss: 0.1040 - val_acc: 0.7308 - val_auc: 0.8848 - val_rec: 0.3636\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.8350 - auc: 0.9273 - rec: 0.6744\n",
      "Epoch 00070: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 783ms/step - loss: 0.0378 - acc: 0.8350 - auc: 0.9273 - rec: 0.6744 - val_loss: 0.1081 - val_acc: 0.6923 - val_auc: 0.8818 - val_rec: 0.2727\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.8544 - auc: 0.9384 - rec: 0.7442\n",
      "Epoch 00071: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 772ms/step - loss: 0.0354 - acc: 0.8544 - auc: 0.9384 - rec: 0.7442 - val_loss: 0.1078 - val_acc: 0.7308 - val_auc: 0.8879 - val_rec: 0.3636\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.7864 - auc: 0.8899 - rec: 0.6047\n",
      "Epoch 00072: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 780ms/step - loss: 0.0451 - acc: 0.7864 - auc: 0.8899 - rec: 0.6047 - val_loss: 0.1173 - val_acc: 0.5769 - val_auc: 0.8909 - val_rec: 0.0000e+00\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0400 - acc: 0.8155 - auc: 0.9079 - rec: 0.6744\n",
      "Epoch 00073: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 795ms/step - loss: 0.0400 - acc: 0.8155 - auc: 0.9079 - rec: 0.6744 - val_loss: 0.1152 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0404 - acc: 0.7670 - auc: 0.9174 - rec: 0.5349\n",
      "Epoch 00074: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 773ms/step - loss: 0.0404 - acc: 0.7670 - auc: 0.9174 - rec: 0.5349 - val_loss: 0.1045 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0462 - acc: 0.7476 - auc: 0.8806 - rec: 0.5349\n",
      "Epoch 00075: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 763ms/step - loss: 0.0462 - acc: 0.7476 - auc: 0.8806 - rec: 0.5349 - val_loss: 0.1084 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0394 - acc: 0.7864 - auc: 0.9198 - rec: 0.5814\n",
      "Epoch 00076: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 793ms/step - loss: 0.0394 - acc: 0.7864 - auc: 0.9198 - rec: 0.5814 - val_loss: 0.1115 - val_acc: 0.5769 - val_auc: 0.8818 - val_rec: 0.0000e+00\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0431 - acc: 0.7961 - auc: 0.9012 - rec: 0.5814\n",
      "Epoch 00077: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 789ms/step - loss: 0.0431 - acc: 0.7961 - auc: 0.9012 - rec: 0.5814 - val_loss: 0.1121 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0426 - acc: 0.7670 - auc: 0.9016 - rec: 0.5814\n",
      "Epoch 00078: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0426 - acc: 0.7670 - auc: 0.9016 - rec: 0.5814 - val_loss: 0.1048 - val_acc: 0.7308 - val_auc: 0.8758 - val_rec: 0.3636\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0376 - acc: 0.8350 - auc: 0.9308 - rec: 0.7442\n",
      "Epoch 00079: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 767ms/step - loss: 0.0376 - acc: 0.8350 - auc: 0.9308 - rec: 0.7442 - val_loss: 0.1067 - val_acc: 0.6154 - val_auc: 0.8758 - val_rec: 0.0909\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.8155 - auc: 0.9312 - rec: 0.6744\n",
      "Epoch 00080: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 811ms/step - loss: 0.0365 - acc: 0.8155 - auc: 0.9312 - rec: 0.6744 - val_loss: 0.1070 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0408 - acc: 0.7864 - auc: 0.9151 - rec: 0.5814\n",
      "Epoch 00081: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 795ms/step - loss: 0.0408 - acc: 0.7864 - auc: 0.9151 - rec: 0.5814 - val_loss: 0.1121 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0367 - acc: 0.8738 - auc: 0.9376 - rec: 0.7674\n",
      "Epoch 00082: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 0.0367 - acc: 0.8738 - auc: 0.9376 - rec: 0.7674 - val_loss: 0.1088 - val_acc: 0.6923 - val_auc: 0.8758 - val_rec: 0.2727\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.8155 - auc: 0.9395 - rec: 0.6977\n",
      "Epoch 00083: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 22s 831ms/step - loss: 0.0370 - acc: 0.8155 - auc: 0.9395 - rec: 0.6977 - val_loss: 0.1048 - val_acc: 0.8077 - val_auc: 0.8758 - val_rec: 0.5455\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0443 - acc: 0.8058 - auc: 0.9072 - rec: 0.7209\n",
      "Epoch 00084: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 806ms/step - loss: 0.0443 - acc: 0.8058 - auc: 0.9072 - rec: 0.7209 - val_loss: 0.1118 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0356 - acc: 0.8641 - auc: 0.9484 - rec: 0.6977\n",
      "Epoch 00085: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 821ms/step - loss: 0.0356 - acc: 0.8641 - auc: 0.9484 - rec: 0.6977 - val_loss: 0.1181 - val_acc: 0.5769 - val_auc: 0.8848 - val_rec: 0.0000e+00\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0373 - acc: 0.7961 - auc: 0.9269 - rec: 0.6512\n",
      "Epoch 00086: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 801ms/step - loss: 0.0373 - acc: 0.7961 - auc: 0.9269 - rec: 0.6512 - val_loss: 0.1270 - val_acc: 0.5769 - val_auc: 0.8818 - val_rec: 0.0000e+00\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.7379 - auc: 0.9037 - rec: 0.5116\n",
      "Epoch 00087: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 791ms/step - loss: 0.0415 - acc: 0.7379 - auc: 0.9037 - rec: 0.5116 - val_loss: 0.1116 - val_acc: 0.7308 - val_auc: 0.8758 - val_rec: 0.3636\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0423 - acc: 0.7864 - auc: 0.9025 - rec: 0.6279\n",
      "Epoch 00088: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 785ms/step - loss: 0.0423 - acc: 0.7864 - auc: 0.9025 - rec: 0.6279 - val_loss: 0.1114 - val_acc: 0.7692 - val_auc: 0.8758 - val_rec: 0.4545\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0387 - acc: 0.8058 - auc: 0.9281 - rec: 0.6512\n",
      "Epoch 00089: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 770ms/step - loss: 0.0387 - acc: 0.8058 - auc: 0.9281 - rec: 0.6512 - val_loss: 0.1107 - val_acc: 0.7308 - val_auc: 0.8758 - val_rec: 0.3636\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0395 - acc: 0.8544 - auc: 0.9161 - rec: 0.7442\n",
      "Epoch 00090: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 814ms/step - loss: 0.0395 - acc: 0.8544 - auc: 0.9161 - rec: 0.7442 - val_loss: 0.1086 - val_acc: 0.7308 - val_auc: 0.8788 - val_rec: 0.3636\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0475 - acc: 0.7767 - auc: 0.8866 - rec: 0.6047\n",
      "Epoch 00091: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 794ms/step - loss: 0.0475 - acc: 0.7767 - auc: 0.8866 - rec: 0.6047 - val_loss: 0.1092 - val_acc: 0.6538 - val_auc: 0.8788 - val_rec: 0.1818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0376 - acc: 0.8155 - auc: 0.9306 - rec: 0.6279\n",
      "Epoch 00092: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 784ms/step - loss: 0.0376 - acc: 0.8155 - auc: 0.9306 - rec: 0.6279 - val_loss: 0.1066 - val_acc: 0.8462 - val_auc: 0.8788 - val_rec: 0.6364\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0462 - acc: 0.8058 - auc: 0.8930 - rec: 0.6744\n",
      "Epoch 00093: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 820ms/step - loss: 0.0462 - acc: 0.8058 - auc: 0.8930 - rec: 0.6744 - val_loss: 0.1078 - val_acc: 0.8462 - val_auc: 0.8788 - val_rec: 0.6364\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.8641 - auc: 0.9374 - rec: 0.7442\n",
      "Epoch 00094: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0386 - acc: 0.8641 - auc: 0.9374 - rec: 0.7442 - val_loss: 0.1029 - val_acc: 0.6923 - val_auc: 0.8788 - val_rec: 0.2727\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.8350 - auc: 0.9252 - rec: 0.6977\n",
      "Epoch 00095: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 794ms/step - loss: 0.0378 - acc: 0.8350 - auc: 0.9252 - rec: 0.6977 - val_loss: 0.1038 - val_acc: 0.6538 - val_auc: 0.8788 - val_rec: 0.1818\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.7961 - auc: 0.9209 - rec: 0.5581\n",
      "Epoch 00096: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 782ms/step - loss: 0.0412 - acc: 0.7961 - auc: 0.9209 - rec: 0.5581 - val_loss: 0.1023 - val_acc: 0.7308 - val_auc: 0.8758 - val_rec: 0.3636\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0369 - acc: 0.8641 - auc: 0.9440 - rec: 0.7907\n",
      "Epoch 00097: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 803ms/step - loss: 0.0369 - acc: 0.8641 - auc: 0.9440 - rec: 0.7907 - val_loss: 0.1030 - val_acc: 0.8077 - val_auc: 0.8788 - val_rec: 0.5455\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0395 - acc: 0.7961 - auc: 0.9219 - rec: 0.6047\n",
      "Epoch 00098: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 811ms/step - loss: 0.0395 - acc: 0.7961 - auc: 0.9219 - rec: 0.6047 - val_loss: 0.1010 - val_acc: 0.7308 - val_auc: 0.8788 - val_rec: 0.3636\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0459 - acc: 0.7767 - auc: 0.8874 - rec: 0.6047\n",
      "Epoch 00099: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 773ms/step - loss: 0.0459 - acc: 0.7767 - auc: 0.8874 - rec: 0.6047 - val_loss: 0.0984 - val_acc: 0.7692 - val_auc: 0.8727 - val_rec: 0.4545\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.8058 - auc: 0.9388 - rec: 0.6744\n",
      "Epoch 00100: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 785ms/step - loss: 0.0353 - acc: 0.8058 - auc: 0.9388 - rec: 0.6744 - val_loss: 0.1090 - val_acc: 0.5769 - val_auc: 0.8667 - val_rec: 0.0000e+00\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.8252 - auc: 0.9442 - rec: 0.6047\n",
      "Epoch 00101: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 0.0374 - acc: 0.8252 - auc: 0.9442 - rec: 0.6047 - val_loss: 0.0979 - val_acc: 0.7308 - val_auc: 0.8788 - val_rec: 0.3636\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0404 - acc: 0.8155 - auc: 0.9048 - rec: 0.7209\n",
      "Epoch 00102: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 805ms/step - loss: 0.0404 - acc: 0.8155 - auc: 0.9048 - rec: 0.7209 - val_loss: 0.1016 - val_acc: 0.8462 - val_auc: 0.8788 - val_rec: 0.6364\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0346 - acc: 0.8350 - auc: 0.9484 - rec: 0.6744\n",
      "Epoch 00103: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 783ms/step - loss: 0.0346 - acc: 0.8350 - auc: 0.9484 - rec: 0.6744 - val_loss: 0.1042 - val_acc: 0.7308 - val_auc: 0.8727 - val_rec: 0.3636\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.7961 - auc: 0.9039 - rec: 0.6279\n",
      "Epoch 00104: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 0.0424 - acc: 0.7961 - auc: 0.9039 - rec: 0.6279 - val_loss: 0.1087 - val_acc: 0.6154 - val_auc: 0.8667 - val_rec: 0.0909\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.8252 - auc: 0.9347 - rec: 0.6512\n",
      "Epoch 00105: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 778ms/step - loss: 0.0378 - acc: 0.8252 - auc: 0.9347 - rec: 0.6512 - val_loss: 0.1309 - val_acc: 0.5769 - val_auc: 0.8576 - val_rec: 0.0000e+00\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0444 - acc: 0.7767 - auc: 0.8928 - rec: 0.6047\n",
      "Epoch 00106: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 785ms/step - loss: 0.0444 - acc: 0.7767 - auc: 0.8928 - rec: 0.6047 - val_loss: 0.1347 - val_acc: 0.5769 - val_auc: 0.8606 - val_rec: 0.0000e+00\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.8447 - auc: 0.9295 - rec: 0.7209\n",
      "Epoch 00107: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 789ms/step - loss: 0.0378 - acc: 0.8447 - auc: 0.9295 - rec: 0.7209 - val_loss: 0.1031 - val_acc: 0.7308 - val_auc: 0.8667 - val_rec: 0.3636\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0368 - acc: 0.8641 - auc: 0.9407 - rec: 0.7907\n",
      "Epoch 00108: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 0.0368 - acc: 0.8641 - auc: 0.9407 - rec: 0.7907 - val_loss: 0.0967 - val_acc: 0.8077 - val_auc: 0.8667 - val_rec: 0.5455\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.7864 - auc: 0.9054 - rec: 0.5814\n",
      "Epoch 00109: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 21s 806ms/step - loss: 0.0417 - acc: 0.7864 - auc: 0.9054 - rec: 0.5814 - val_loss: 0.1226 - val_acc: 0.5769 - val_auc: 0.8667 - val_rec: 0.0000e+00\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.8252 - auc: 0.9438 - rec: 0.6744\n",
      "Epoch 00110: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 22s 830ms/step - loss: 0.0354 - acc: 0.8252 - auc: 0.9438 - rec: 0.6744 - val_loss: 0.1178 - val_acc: 0.5769 - val_auc: 0.8788 - val_rec: 0.0000e+00\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0394 - acc: 0.7864 - auc: 0.9209 - rec: 0.5814\n",
      "Epoch 00111: val_acc did not improve from 0.84615\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 0.0394 - acc: 0.7864 - auc: 0.9209 - rec: 0.5814 - val_loss: 0.1186 - val_acc: 0.5769 - val_auc: 0.8606 - val_rec: 0.0000e+00\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0362 - acc: 0.8641 - auc: 0.9430 - rec: 0.7209\n",
      "Epoch 00112: val_acc improved from 0.84615 to 0.88462, saving model to chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n",
      "26/26 [==============================] - 22s 830ms/step - loss: 0.0362 - acc: 0.8641 - auc: 0.9430 - rec: 0.7209 - val_loss: 0.1057 - val_acc: 0.8846 - val_auc: 0.8788 - val_rec: 0.7273\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0411 - acc: 0.8252 - auc: 0.9124 - rec: 0.6744\n",
      "Epoch 00113: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 795ms/step - loss: 0.0411 - acc: 0.8252 - auc: 0.9124 - rec: 0.6744 - val_loss: 0.1185 - val_acc: 0.5769 - val_auc: 0.8636 - val_rec: 0.0000e+00\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0490 - acc: 0.6699 - auc: 0.8467 - rec: 0.4419\n",
      "Epoch 00114: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 810ms/step - loss: 0.0490 - acc: 0.6699 - auc: 0.8467 - rec: 0.4419 - val_loss: 0.1249 - val_acc: 0.5769 - val_auc: 0.8515 - val_rec: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0326 - acc: 0.8252 - auc: 0.9560 - rec: 0.6512\n",
      "Epoch 00115: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 796ms/step - loss: 0.0326 - acc: 0.8252 - auc: 0.9560 - rec: 0.6512 - val_loss: 0.1026 - val_acc: 0.8077 - val_auc: 0.8697 - val_rec: 0.5455\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0355 - acc: 0.8835 - auc: 0.9432 - rec: 0.7674\n",
      "Epoch 00116: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 0.0355 - acc: 0.8835 - auc: 0.9432 - rec: 0.7674 - val_loss: 0.1046 - val_acc: 0.8462 - val_auc: 0.8758 - val_rec: 0.7273\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0410 - acc: 0.7282 - auc: 0.8986 - rec: 0.5116\n",
      "Epoch 00117: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 790ms/step - loss: 0.0410 - acc: 0.7282 - auc: 0.8986 - rec: 0.5116 - val_loss: 0.1045 - val_acc: 0.8462 - val_auc: 0.8667 - val_rec: 0.7273\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0397 - acc: 0.8738 - auc: 0.9221 - rec: 0.8372\n",
      "Epoch 00118: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 788ms/step - loss: 0.0397 - acc: 0.8738 - auc: 0.9221 - rec: 0.8372 - val_loss: 0.1085 - val_acc: 0.8077 - val_auc: 0.8667 - val_rec: 0.7273\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0305 - acc: 0.9223 - auc: 0.9663 - rec: 0.8605\n",
      "Epoch 00119: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 795ms/step - loss: 0.0305 - acc: 0.9223 - auc: 0.9663 - rec: 0.8605 - val_loss: 0.1026 - val_acc: 0.8077 - val_auc: 0.8667 - val_rec: 0.5455\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0427 - acc: 0.7670 - auc: 0.9027 - rec: 0.5349\n",
      "Epoch 00120: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 797ms/step - loss: 0.0427 - acc: 0.7670 - auc: 0.9027 - rec: 0.5349 - val_loss: 0.1224 - val_acc: 0.5769 - val_auc: 0.8424 - val_rec: 0.0000e+00\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.7961 - auc: 0.9382 - rec: 0.5814\n",
      "Epoch 00121: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 786ms/step - loss: 0.0365 - acc: 0.7961 - auc: 0.9382 - rec: 0.5814 - val_loss: 0.1095 - val_acc: 0.6923 - val_auc: 0.8545 - val_rec: 0.2727\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0356 - acc: 0.8350 - auc: 0.9345 - rec: 0.7209\n",
      "Epoch 00122: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 773ms/step - loss: 0.0356 - acc: 0.8350 - auc: 0.9345 - rec: 0.7209 - val_loss: 0.1209 - val_acc: 0.6154 - val_auc: 0.8636 - val_rec: 0.0909\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.7961 - auc: 0.9124 - rec: 0.6512\n",
      "Epoch 00123: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 797ms/step - loss: 0.0403 - acc: 0.7961 - auc: 0.9124 - rec: 0.6512 - val_loss: 0.1492 - val_acc: 0.5769 - val_auc: 0.8424 - val_rec: 0.0000e+00\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0361 - acc: 0.7670 - auc: 0.9401 - rec: 0.5116\n",
      "Epoch 00124: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 0.0361 - acc: 0.7670 - auc: 0.9401 - rec: 0.5116 - val_loss: 0.1241 - val_acc: 0.5769 - val_auc: 0.8455 - val_rec: 0.0000e+00\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.8835 - auc: 0.9568 - rec: 0.7674\n",
      "Epoch 00125: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 0.0333 - acc: 0.8835 - auc: 0.9568 - rec: 0.7674 - val_loss: 0.1102 - val_acc: 0.8462 - val_auc: 0.8788 - val_rec: 0.7273\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0325 - acc: 0.8155 - auc: 0.9432 - rec: 0.7209\n",
      "Epoch 00126: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 783ms/step - loss: 0.0325 - acc: 0.8155 - auc: 0.9432 - rec: 0.7209 - val_loss: 0.1118 - val_acc: 0.8462 - val_auc: 0.8848 - val_rec: 0.6364\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.8835 - auc: 0.9438 - rec: 0.8140\n",
      "Epoch 00127: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 795ms/step - loss: 0.0354 - acc: 0.8835 - auc: 0.9438 - rec: 0.8140 - val_loss: 0.1089 - val_acc: 0.7308 - val_auc: 0.8636 - val_rec: 0.3636\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9126 - auc: 0.9663 - rec: 0.8372\n",
      "Epoch 00128: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.0306 - acc: 0.9126 - auc: 0.9663 - rec: 0.8372 - val_loss: 0.1113 - val_acc: 0.6923 - val_auc: 0.8576 - val_rec: 0.2727\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.7476 - auc: 0.9031 - rec: 0.5581\n",
      "Epoch 00129: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.0412 - acc: 0.7476 - auc: 0.9031 - rec: 0.5581 - val_loss: 0.1349 - val_acc: 0.5769 - val_auc: 0.8515 - val_rec: 0.0000e+00\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.7476 - auc: 0.9025 - rec: 0.5349\n",
      "Epoch 00130: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.0413 - acc: 0.7476 - auc: 0.9025 - rec: 0.5349 - val_loss: 0.1012 - val_acc: 0.8846 - val_auc: 0.8667 - val_rec: 0.7273\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0391 - acc: 0.7961 - auc: 0.9223 - rec: 0.6047\n",
      "Epoch 00131: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 804ms/step - loss: 0.0391 - acc: 0.7961 - auc: 0.9223 - rec: 0.6047 - val_loss: 0.1579 - val_acc: 0.5769 - val_auc: 0.8485 - val_rec: 0.0000e+00\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0397 - acc: 0.8252 - auc: 0.9267 - rec: 0.6279\n",
      "Epoch 00132: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 794ms/step - loss: 0.0397 - acc: 0.8252 - auc: 0.9267 - rec: 0.6279 - val_loss: 0.1574 - val_acc: 0.5769 - val_auc: 0.8545 - val_rec: 0.0000e+00\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0379 - acc: 0.8252 - auc: 0.9256 - rec: 0.6744\n",
      "Epoch 00133: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 783ms/step - loss: 0.0379 - acc: 0.8252 - auc: 0.9256 - rec: 0.6744 - val_loss: 0.1019 - val_acc: 0.8846 - val_auc: 0.8697 - val_rec: 0.7273\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0379 - acc: 0.8058 - auc: 0.9225 - rec: 0.6977\n",
      "Epoch 00134: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0379 - acc: 0.8058 - auc: 0.9225 - rec: 0.6977 - val_loss: 0.1044 - val_acc: 0.8462 - val_auc: 0.8758 - val_rec: 0.7273\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0348 - acc: 0.8252 - auc: 0.9481 - rec: 0.6279\n",
      "Epoch 00135: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 777ms/step - loss: 0.0348 - acc: 0.8252 - auc: 0.9481 - rec: 0.6279 - val_loss: 0.1017 - val_acc: 0.7308 - val_auc: 0.8515 - val_rec: 0.3636\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0372 - acc: 0.8252 - auc: 0.9281 - rec: 0.6977\n",
      "Epoch 00136: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 782ms/step - loss: 0.0372 - acc: 0.8252 - auc: 0.9281 - rec: 0.6977 - val_loss: 0.1137 - val_acc: 0.7308 - val_auc: 0.8515 - val_rec: 0.3636\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0350 - acc: 0.7767 - auc: 0.9591 - rec: 0.4884\n",
      "Epoch 00137: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 785ms/step - loss: 0.0350 - acc: 0.7767 - auc: 0.9591 - rec: 0.4884 - val_loss: 0.1290 - val_acc: 0.5769 - val_auc: 0.8455 - val_rec: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0315 - acc: 0.8350 - auc: 0.9624 - rec: 0.6744\n",
      "Epoch 00138: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0315 - acc: 0.8350 - auc: 0.9624 - rec: 0.6744 - val_loss: 0.1295 - val_acc: 0.6154 - val_auc: 0.8576 - val_rec: 0.0909\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0345 - acc: 0.8835 - auc: 0.9446 - rec: 0.8372\n",
      "Epoch 00139: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 797ms/step - loss: 0.0345 - acc: 0.8835 - auc: 0.9446 - rec: 0.8372 - val_loss: 0.1260 - val_acc: 0.8462 - val_auc: 0.8788 - val_rec: 0.7273\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0387 - acc: 0.8447 - auc: 0.9252 - rec: 0.6977\n",
      "Epoch 00140: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 805ms/step - loss: 0.0387 - acc: 0.8447 - auc: 0.9252 - rec: 0.6977 - val_loss: 0.1246 - val_acc: 0.5769 - val_auc: 0.8424 - val_rec: 0.0000e+00\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.8058 - auc: 0.9347 - rec: 0.6279\n",
      "Epoch 00141: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 787ms/step - loss: 0.0374 - acc: 0.8058 - auc: 0.9347 - rec: 0.6279 - val_loss: 0.1017 - val_acc: 0.7692 - val_auc: 0.8424 - val_rec: 0.4545\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.8835 - auc: 0.9740 - rec: 0.7907\n",
      "Epoch 00142: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 818ms/step - loss: 0.0283 - acc: 0.8835 - auc: 0.9740 - rec: 0.7907 - val_loss: 0.1083 - val_acc: 0.8462 - val_auc: 0.8667 - val_rec: 0.7273\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.8641 - auc: 0.9564 - rec: 0.7674\n",
      "Epoch 00143: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 0.0314 - acc: 0.8641 - auc: 0.9564 - rec: 0.7674 - val_loss: 0.1024 - val_acc: 0.8846 - val_auc: 0.8485 - val_rec: 0.7273\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0326 - acc: 0.8932 - auc: 0.9506 - rec: 0.8140\n",
      "Epoch 00144: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 802ms/step - loss: 0.0326 - acc: 0.8932 - auc: 0.9506 - rec: 0.8140 - val_loss: 0.1000 - val_acc: 0.8846 - val_auc: 0.8485 - val_rec: 0.7273\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0323 - acc: 0.8738 - auc: 0.9574 - rec: 0.8140\n",
      "Epoch 00145: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 20s 780ms/step - loss: 0.0323 - acc: 0.8738 - auc: 0.9574 - rec: 0.8140 - val_loss: 0.1090 - val_acc: 0.6923 - val_auc: 0.8515 - val_rec: 0.2727\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.9126 - auc: 0.9622 - rec: 0.8605\n",
      "Epoch 00146: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 796ms/step - loss: 0.0297 - acc: 0.9126 - auc: 0.9622 - rec: 0.8605 - val_loss: 0.1060 - val_acc: 0.8462 - val_auc: 0.8636 - val_rec: 0.6364\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.8544 - auc: 0.9308 - rec: 0.7442\n",
      "Epoch 00147: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 22s 839ms/step - loss: 0.0353 - acc: 0.8544 - auc: 0.9308 - rec: 0.7442 - val_loss: 0.1027 - val_acc: 0.8077 - val_auc: 0.8515 - val_rec: 0.5455\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0335 - acc: 0.8641 - auc: 0.9450 - rec: 0.7442\n",
      "Epoch 00148: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 22s 832ms/step - loss: 0.0335 - acc: 0.8641 - auc: 0.9450 - rec: 0.7442 - val_loss: 0.1142 - val_acc: 0.8462 - val_auc: 0.8485 - val_rec: 0.7273\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0324 - acc: 0.8447 - auc: 0.9516 - rec: 0.7209\n",
      "Epoch 00149: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 826ms/step - loss: 0.0324 - acc: 0.8447 - auc: 0.9516 - rec: 0.7209 - val_loss: 0.1220 - val_acc: 0.6154 - val_auc: 0.8394 - val_rec: 0.0909\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0300 - acc: 0.8738 - auc: 0.9638 - rec: 0.8140\n",
      "Epoch 00150: val_acc did not improve from 0.88462\n",
      "26/26 [==============================] - 21s 798ms/step - loss: 0.0300 - acc: 0.8738 - auc: 0.9638 - rec: 0.8140 - val_loss: 0.1267 - val_acc: 0.6538 - val_auc: 0.8424 - val_rec: 0.1818\n"
     ]
    }
   ],
   "source": [
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 150\n",
    "history = model.fit(train_dataset,validation_data=validation_dataset,\n",
    "                    epochs=epochs,shuffle=True,verbose=1,\n",
    "                    callbacks=[checkpoint_cb,\n",
    "                              #  early_stopping_cb,\n",
    "                               tensorboard_callback,\n",
    "                              ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3678090,
     "status": "ok",
     "timestamp": 1610353416010,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "TiCu9ooJ3OOm",
    "outputId": "f4463f4c-8c51-4b56-8806-f68e4b46ec64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chekpoint/lacune/154_lacune_batch-4_wce_relu_aug_Adam-lr_1e-5_cv3_t1_cw.h5\n"
     ]
    }
   ],
   "source": [
    "weight_path=save_path+checkpoint_name+'.h5'\n",
    "print(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3680645,
     "status": "ok",
     "timestamp": 1610353418575,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "o1Nkc5QqJ2Qt",
    "outputId": "349673b9-fefa-4101-f6a4-7c0823b14d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "(None, 30, 95, 95, 64)\n",
      "(None, 14, 46, 93, 64)\n",
      "(None, 6, 22, 91, 128)\n",
      "(None, 2, 10, 89, 256)\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Loading and preprocessing test data...')\n",
    "print('-'*30)\n",
    "imgs_test = x_val\n",
    "imgs_mask_test = imgs_label_valid\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print('Loading saved weights...')\n",
    "print('-'*30)\n",
    "\n",
    "model = get_model(depth=32, width=192, height=192, class_num=1)\n",
    "\n",
    "\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3682005,
     "status": "ok",
     "timestamp": 1610353419944,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "_7uVyTiOLRGF",
    "outputId": "211e0e04-31e2-4cfb-d4ff-8fa0c412f642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "Results = model.predict(imgs_test, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3681997,
     "status": "ok",
     "timestamp": 1610353419945,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "tYLc1U_cLXBW",
    "outputId": "2f1e0b8d-2bcf-49da-ab34-9ba3522e22de"
   },
   "outputs": [],
   "source": [
    "argmax_pred = np.reshape((Results>0.5).astype(int),(len(Results)))\n",
    "argmax_truth = imgs_label_valid.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|0 = Lacune |  | 1 = Non-Lacune|\n",
      "\n",
      "   nii name  Prediction  GroundTruth\n",
      "0    is0136           1            1\n",
      "1    is0125           0            1\n",
      "2    is0132           1            1\n",
      "3    is0038           1            1\n",
      "4    is0067           1            1\n",
      "5    is0074           1            1\n",
      "6    is0001           1            1\n",
      "7    is0031           1            1\n",
      "8    is0008           1            1\n",
      "9    is0082           0            1\n",
      "10   is0127           0            1\n",
      "11   is0029           0            0\n",
      "12   is0072           0            0\n",
      "13   is0056           0            0\n",
      "14   is0083           0            0\n",
      "15   is0040           0            0\n",
      "16   is0071           0            0\n",
      "17   is0145           0            0\n",
      "18   is0021           0            0\n",
      "19   is0077           0            0\n",
      "20   is0039           0            0\n",
      "21   is0041           0            0\n",
      "22   is0004           0            0\n",
      "23   is0111           0            0\n",
      "24   is0007           0            0\n",
      "25   is0047           0            0\n"
     ]
    }
   ],
   "source": [
    "Pred_dict ={}\n",
    "Trut_dict ={}\n",
    "nii_data=[]\n",
    "count = 0\n",
    "for i in valid_path:\n",
    "    nii_data.append(i[-14:-8])\n",
    "\n",
    "result_df = {'nii name':nii_data,\n",
    "             'Prediction': argmax_pred,\n",
    "             'GroundTruth':argmax_truth\n",
    "            }\n",
    "results_df = pd.DataFrame(result_df)\n",
    "print('|0 = Lacune |  | 1 = Non-Lacune|\\n')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3681989,
     "status": "ok",
     "timestamp": 1610353419946,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "kLHP27DBKgM3",
    "outputId": "0af47f34-e216-4219-9f49-16982cfb9f39"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "cm = confusion_matrix(argmax_truth, argmax_pred)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 3681981,
     "status": "ok",
     "timestamp": 1610353419947,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "ZzwQ5wM0L1WA"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "imgs_test = imgs_valid\n",
    "imgs_mask_test = imgs_label_valid\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90,fontsize=15)\n",
    "    plt.yticks(tick_marks, classes,fontsize=15)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=20)\n",
    "    \n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label',fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "executionInfo": {
     "elapsed": 3682411,
     "status": "ok",
     "timestamp": 1610353420384,
     "user": {
      "displayName": "簡志宇",
      "photoUrl": "",
      "userId": "16413035766833027426"
     },
     "user_tz": -480
    },
    "id": "0K_IFsTPMLR3",
    "outputId": "afd16f29-17eb-4e72-a0c3-6cb2c3146136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# species =['Normal','Anterior','Posterior']\n",
    "species = ['Lacune', 'Non-Lacune']\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm, species)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOoc17vCy4MNWnxWrYdAXWh",
   "collapsed_sections": [],
   "mount_file_id": "1wlJ7_wWCbZnRZQ_Pu7G6CKSyEJ7C5vbZ",
   "name": "MRI_mask-image_classification_for_lacuneclass.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
